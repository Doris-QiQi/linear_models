---
title: "Bootstrapping"
author: "Jingyi Yao"
date: "`r Sys.Date()`"
output: github_document
---

## Introduction to Bootstrap

Bootstrapping is a popular resampling-based approach to statistical inference, and is helpful when usual statistical methods are intractable or inappropriate. The idea is to **draw repeated samples** from your original sample with **replacement**, thereby **approximating** the repeated sampling framework. Using list columns to store bootstrap samples is natural and provides a “tidy” approach to resampling-based inference.


Traditionally, the **distribution of a sample statistic** (sample mean, SLR coefficients, etc.) for repeated, random draws from a population has been established theoretically. These **theoretical distributions** make some **assumptions** about the **underlying population** from which samples are drawn, or depend on **large sample sizes** for asymptotic results. (Central Limit Theorem)


In cases where the **assumptions aren’t met**, or **sample sizes aren’t large enough** for asymptotics to kick in, it is still necessary to make inferences using the sample statistic. In these cases, **drawing repeatedly from the original population** would be great – one could simply draw a lot of samples and look at the **empirical** (rather than theoretical) distribution. 


Repeated sampling can happen on a computer though. To bootstrap, one draws repeated samples (with the **same sample size**) from the original sample with replacement to mimic the process of drawing repeated samples from the population. The bootstrap samples will differ from the original sample, and the sample statistic of interest (sample mean, SLR coefficients, etc.) can be computed for each bootstrap sample. Looking at the distribution of the statistic across samples gives a sense of the uncertainty in the estimate.


```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

set.seed(1)
```


## Bootstrapping in SLR

### 1. generate 2 samples

#### const sample has the same error for each y -- linear regression assumption

#### nonconst sample has different error for each y
```{r}
n_samp = 250

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)

```


### 2. bind the 2 samples 

#### `bind_rows(.id = "new column", a = df1, b = df2)` a and b are in new column
```{r}
sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "data_source") 

sim_df
```


### 3. plot the fitted line using `+ stat_smooth(method = "lm")`
```{r}
sim_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  facet_grid(~data_source) 

```


These datasets have roughly the same overall variance, but the left panel shows data with constant variance and the **right panel** shows data with **non-constant variance**. For this reason, ordinary least squares should provide reasonable estimates in both cases, but inference is standard inference approaches may only be justified for the data on the left.


### 4. compare the SLR model results
```{r}
lm(y ~ x, data = sim_df_const) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

```


```{r}
lm(y ~ x, data = sim_df_nonconst) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

```


standard errors for coefficient estimates are similar in both cases.



## Drawing one bootstrap sample
```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
```


```{r}
boot_sample(sim_df_nonconst) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm")

```


## Drawing many bootstrap samples
```{r}
boot_straps = 
  data_frame(
    strap_number = 1:1000,
    strap_sample = rerun(1000, boot_sample(sim_df_nonconst))
  )

boot_straps

```


```{r}
boot_straps %>% 
  filter(strap_number %in% 1:2) %>% 
  mutate(strap_sample = map(strap_sample, ~arrange(.x, x))) %>% 
  pull(strap_sample)

```


```{r}
boot_straps %>% 
  filter(strap_number %in% 1:3) %>% 
  unnest(strap_sample) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm", se = FALSE) +
  facet_grid(~strap_number) 

```


## Analyzing bootstrap samples
```{r}
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(y ~ x, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

bootstrap_results %>% 
  group_by(term) %>% 
  summarize(boot_se = sd(estimate)) %>% 
  knitr::kable(digits = 3)

```


```{r}
bootstrap_results %>% 
  group_by(term) %>% 
  summarize(
    ci_lower = quantile(estimate, 0.025), 
    ci_upper = quantile(estimate, 0.975))

```


```{r}
boot_straps %>% 
  unnest(strap_sample) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_line(aes(group = strap_number), stat = "smooth", method = "lm", se = FALSE, alpha = .1, color = "blue") +
  geom_point(data = sim_df_nonconst, alpha = .5)

```


## bootstrap in modelr
```{r}


```